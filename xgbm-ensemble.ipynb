{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":70942,"databundleVersionId":10381525,"sourceType":"competition"},{"sourceId":211253469,"sourceType":"kernelVersion"},{"sourceId":211322530,"sourceType":"kernelVersion"}],"dockerImageVersionId":30805,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pip Install Libraries for Metric\nSince internet must be turned off for submission, we pip install from my other notebook [here][1] where I downloaded the WHL files.\n\n[1]: https://www.kaggle.com/code/cdeotte/pip-install-lifelines","metadata":{}},{"cell_type":"code","source":"!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-10T07:56:19.574115Z","iopub.execute_input":"2024-12-10T07:56:19.574371Z","iopub.status.idle":"2024-12-10T07:59:44.560496Z","shell.execute_reply.started":"2024-12-10T07:56:19.574338Z","shell.execute_reply":"2024-12-10T07:59:44.559417Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Train and Test","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\n\ntest = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\nprint(\"Test shape:\", test.shape )\n\ntrain = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\nprint(\"Train shape:\",train.shape)\ntrain.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:59:44.565080Z","iopub.execute_input":"2024-12-10T07:59:44.565347Z","iopub.status.idle":"2024-12-10T07:59:45.242166Z","shell.execute_reply.started":"2024-12-10T07:59:44.565317Z","shell.execute_reply":"2024-12-10T07:59:45.241379Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA on Train Targets\nThere are two train targets `efs` and `efs_time`. When `efs==1` we know patient **had an event** and we know time of event is `efs_time`. When `efs==0` we **do not know** if patient had an event or not, but we do know that patient was **without event for at least** `efs_time`.","metadata":{}},{"cell_type":"code","source":"plt.hist(train.loc[train.efs==1,\"efs_time\"],bins=100,label=\"efs=1, Yes Event\")\nplt.hist(train.loc[train.efs==0,\"efs_time\"],bins=100,label=\"efs=0, Maybe Event\")\nplt.xlabel(\"Time of Observation, efs_time\")\nplt.ylabel(\"Density\")\nplt.title(\"Times of Observation. Either time to event, or time observed without event.\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:59:45.244320Z","iopub.execute_input":"2024-12-10T07:59:45.245057Z","iopub.status.idle":"2024-12-10T07:59:45.821416Z","shell.execute_reply.started":"2024-12-10T07:59:45.245030Z","shell.execute_reply":"2024-12-10T07:59:45.820556Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transform Two Targets into One Target with KaplanMeier!\nBoth targets `efs` and `efs_time` provide useful information. We will tranform these two targets into a single target to train our model with. In this competition we need to predict `risk score`. So we will create a target that mimics `risk score` to train our model. (Note this is only one out of many ways to transform two targets into one target. Considering experimenting on your own).","metadata":{}},{"cell_type":"code","source":"from lifelines import KaplanMeierFitter\ndef transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n    kmf = KaplanMeierFitter()\n    kmf.fit(df[time_col], df[event_col])\n    y = kmf.survival_function_at_times(df[time_col]).values\n    return y\ntrain[\"y\"] = transform_survival_probability(train, time_col='efs_time', event_col='efs')\n\nplt.hist(train.loc[train.efs==1,\"y\"],bins=100,label=\"efs=1, Yes Event\")\nplt.hist(train.loc[train.efs==0,\"y\"],bins=100,label=\"efs=0, Maybe Event\")\nplt.xlabel(\"Transformed Target y\")\nplt.ylabel(\"Density\")\nplt.title(\"KaplanMeier Transformed Target y using both efs and efs_time.\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:59:45.822587Z","iopub.execute_input":"2024-12-10T07:59:45.822825Z","iopub.status.idle":"2024-12-10T07:59:46.815102Z","shell.execute_reply.started":"2024-12-10T07:59:45.822801Z","shell.execute_reply":"2024-12-10T07:59:46.814337Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Features\nThere are a total of 57 features. From these 35 are categorical and 22 are numerical. We will label encode the categorical features. Then our XGB and CAT model will accept these as categorical features and process them special internally. We leave the numerical feature NANs as NANs because GBDT (like XGB and CAT) can handle NAN and will use this information.","metadata":{}},{"cell_type":"code","source":"RMV = [\"ID\",\"efs\",\"efs_time\",\"y\"]\nFEATURES = [c for c in train.columns if not c in RMV]\nprint(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:59:46.816383Z","iopub.execute_input":"2024-12-10T07:59:46.817340Z","iopub.status.idle":"2024-12-10T07:59:46.822694Z","shell.execute_reply.started":"2024-12-10T07:59:46.817284Z","shell.execute_reply":"2024-12-10T07:59:46.821904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CATS = []\nfor c in FEATURES:\n    if train[c].dtype==\"object\":\n        CATS.append(c)\n        train[c] = train[c].fillna(\"NAN\")\n        test[c] = test[c].fillna(\"NAN\")\nprint(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:59:46.823957Z","iopub.execute_input":"2024-12-10T07:59:46.824601Z","iopub.status.idle":"2024-12-10T07:59:46.920499Z","shell.execute_reply.started":"2024-12-10T07:59:46.824551Z","shell.execute_reply":"2024-12-10T07:59:46.919732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined = pd.concat([train,test],axis=0,ignore_index=True)\n#print(\"Combined data shape:\", combined.shape )\n\n# LABEL ENCODE CATEGORICAL FEATURES\nprint(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\nfor c in FEATURES:\n\n    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n    if c in CATS:\n        print(f\"{c}, \",end=\"\")\n        combined[c],_ = combined[c].factorize()\n        combined[c] -= combined[c].min()\n        combined[c] = combined[c].astype(\"int32\")\n        combined[c] = combined[c].astype(\"category\")\n        \n    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n    else:\n        if combined[c].dtype==\"float64\":\n            combined[c] = combined[c].astype(\"float32\")\n        if combined[c].dtype==\"int64\":\n            combined[c] = combined[c].astype(\"int32\")\n    \ntrain = combined.iloc[:len(train)].copy()\ntest = combined.iloc[len(train):].reset_index(drop=True).copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:59:46.921630Z","iopub.execute_input":"2024-12-10T07:59:46.922252Z","iopub.status.idle":"2024-12-10T07:59:47.059295Z","shell.execute_reply.started":"2024-12-10T07:59:46.922213Z","shell.execute_reply":"2024-12-10T07:59:47.058409Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XGBoost with KaplanMeier\nWe train XGBoost model for 10 folds and achieve **CV 0.674**!","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom xgboost import XGBRegressor, XGBClassifier\nimport xgboost as xgb\nprint(\"Using XGBoost version\",xgb.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:59:47.060618Z","iopub.execute_input":"2024-12-10T07:59:47.061396Z","iopub.status.idle":"2024-12-10T07:59:47.357340Z","shell.execute_reply.started":"2024-12-10T07:59:47.061357Z","shell.execute_reply":"2024-12-10T07:59:47.356477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nFOLDS = 10\nkf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n    \noof_xgb = np.zeros(len(train))\npred_xgb = np.zeros(len(test))\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {i+1}\")\n    print(\"#\"*25)\n    \n    x_train = train.loc[train_index,FEATURES].copy()\n    y_train = train.loc[train_index,\"y\"]\n    x_valid = train.loc[test_index,FEATURES].copy()\n    y_valid = train.loc[test_index,\"y\"]\n    x_test = test[FEATURES].copy()\n\n    model_xgb = XGBRegressor(\n        device=\"cuda\",\n        max_depth=3,  \n        colsample_bytree=0.5,  \n        subsample=0.8,  \n        n_estimators=2000,  \n        learning_rate=0.02,  \n        enable_categorical=True,\n        min_child_weight=80,\n        #early_stopping_rounds=25,\n    )\n    model_xgb.fit(\n        x_train, y_train,\n        eval_set=[(x_valid, y_valid)],  \n        verbose=500 \n    )\n\n    # INFER OOF\n    oof_xgb[test_index] = model_xgb.predict(x_valid)\n    # INFER TEST\n    pred_xgb += model_xgb.predict(x_test)\n\n# COMPUTE AVERAGE TEST PREDS\npred_xgb /= FOLDS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:59:47.361291Z","iopub.execute_input":"2024-12-10T07:59:47.361625Z","iopub.status.idle":"2024-12-10T08:00:39.691597Z","shell.execute_reply.started":"2024-12-10T07:59:47.361588Z","shell.execute_reply":"2024-12-10T08:00:39.690774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from metric import score\n\ny_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\ny_pred = train[[\"ID\"]].copy()\ny_pred[\"prediction\"] = oof_xgb\nm = score(y_true.copy(), y_pred.copy(), \"ID\")\nprint(f\"\\nOverall CV for XGBoost KaplanMeier =\",m)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:00:39.692803Z","iopub.execute_input":"2024-12-10T08:00:39.693190Z","iopub.status.idle":"2024-12-10T08:00:40.031424Z","shell.execute_reply.started":"2024-12-10T08:00:39.693147Z","shell.execute_reply":"2024-12-10T08:00:40.030571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_importance = model_xgb.feature_importances_\nimportance_df = pd.DataFrame({\n    \"Feature\": FEATURES,  # Replace FEATURES with your list of feature names\n    \"Importance\": feature_importance\n}).sort_values(by=\"Importance\", ascending=False)\nplt.figure(figsize=(10, 15))\nplt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\nplt.xlabel(\"Importance\")\nplt.ylabel(\"Feature\")\nplt.title(\"XGBoost KaplanMeier Feature Importance\")\nplt.gca().invert_yaxis()  # Flip features for better readability\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:00:40.032710Z","iopub.execute_input":"2024-12-10T08:00:40.033117Z","iopub.status.idle":"2024-12-10T08:00:40.722487Z","shell.execute_reply.started":"2024-12-10T08:00:40.033075Z","shell.execute_reply":"2024-12-10T08:00:40.721592Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CatBoost with KaplanMeier\nWe train CatBoost model for 10 folds and achieve **CV 0.674**!","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor, CatBoostClassifier\nimport catboost as cb\nprint(\"Using CatBoost version\",cb.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:00:40.723843Z","iopub.execute_input":"2024-12-10T08:00:40.724487Z","iopub.status.idle":"2024-12-10T08:00:40.971234Z","shell.execute_reply.started":"2024-12-10T08:00:40.724441Z","shell.execute_reply":"2024-12-10T08:00:40.970508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nFOLDS = 10\nkf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n    \noof_cat = np.zeros(len(train))\npred_cat = np.zeros(len(test))\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {i+1}\")\n    print(\"#\"*25)\n    \n    x_train = train.loc[train_index,FEATURES].copy()\n    y_train = train.loc[train_index,\"y\"]\n    x_valid = train.loc[test_index,FEATURES].copy()\n    y_valid = train.loc[test_index,\"y\"]\n    x_test = test[FEATURES].copy()\n\n    model_cat = CatBoostRegressor(\n        task_type=\"GPU\",  \n        learning_rate=0.1,    \n        grow_policy='Lossguide',\n        #early_stopping_rounds=25,\n    )\n    model_cat.fit(x_train,y_train,\n              eval_set=(x_valid, y_valid),\n              cat_features=CATS,\n              verbose=250)\n\n    # INFER OOF\n    oof_cat[test_index] = model_cat.predict(x_valid)\n    # INFER TEST\n    pred_cat += model_cat.predict(x_test)\n\n# COMPUTE AVERAGE TEST PREDS\npred_cat /= FOLDS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:00:40.972257Z","iopub.execute_input":"2024-12-10T08:00:40.972628Z","iopub.status.idle":"2024-12-10T08:04:11.426343Z","shell.execute_reply.started":"2024-12-10T08:00:40.972590Z","shell.execute_reply":"2024-12-10T08:04:11.425333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\ny_pred = train[[\"ID\"]].copy()\ny_pred[\"prediction\"] = oof_cat\nm = score(y_true.copy(), y_pred.copy(), \"ID\")\nprint(f\"\\nOverall CV for CatBoost KaplanMeier =\",m)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:04:11.427690Z","iopub.execute_input":"2024-12-10T08:04:11.428086Z","iopub.status.idle":"2024-12-10T08:04:11.764889Z","shell.execute_reply.started":"2024-12-10T08:04:11.428044Z","shell.execute_reply":"2024-12-10T08:04:11.763848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_importance = model_cat.get_feature_importance()\nimportance_df = pd.DataFrame({\n    \"Feature\": FEATURES, \n    \"Importance\": feature_importance\n}).sort_values(by=\"Importance\", ascending=False)\nplt.figure(figsize=(10, 15))\nplt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\nplt.xlabel(\"Importance\")\nplt.ylabel(\"Feature\")\nplt.title(\"CatBoost KaplanMeier Feature Importance\")\nplt.gca().invert_yaxis()  # Flip features for better readability\nplt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T08:04:11.766111Z","iopub.execute_input":"2024-12-10T08:04:11.766493Z","iopub.status.idle":"2024-12-10T08:04:12.422053Z","shell.execute_reply.started":"2024-12-10T08:04:11.766439Z","shell.execute_reply":"2024-12-10T08:04:12.421229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LightGBM with KaplanMeier\nWe train LightGBM model for 10 folds and achieve **CV 0.6725**!","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nimport lightgbm as lgb\nprint(\"Using LightGBM version\",lgb.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:04:12.423031Z","iopub.execute_input":"2024-12-10T08:04:12.423303Z","iopub.status.idle":"2024-12-10T08:04:14.663986Z","shell.execute_reply.started":"2024-12-10T08:04:12.423277Z","shell.execute_reply":"2024-12-10T08:04:14.663132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FOLDS = 10\nkf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n    \noof_lgb = np.zeros(len(train))\npred_lgb = np.zeros(len(test))\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {i+1}\")\n    print(\"#\"*25)\n    \n    x_train = train.loc[train_index,FEATURES].copy()\n    y_train = train.loc[train_index,\"y\"]    \n    x_valid = train.loc[test_index,FEATURES].copy()\n    y_valid = train.loc[test_index,\"y\"]\n    x_test = test[FEATURES].copy()\n\n    model_lgb = LGBMRegressor(\n        device=\"gpu\", \n        max_depth=3, \n        colsample_bytree=0.4,  \n        #subsample=0.9, \n        n_estimators=2500, \n        learning_rate=0.02, \n        objective=\"regression\", \n        verbose=-1, \n        #early_stopping_rounds=25,\n    )\n    model_lgb.fit(\n        x_train, y_train,\n        eval_set=[(x_valid, y_valid)],\n    )\n    \n    # INFER OOF\n    oof_lgb[test_index] = model_lgb.predict(x_valid)\n    # INFER TEST\n    pred_lgb += model_lgb.predict(x_test)\n\n# COMPUTE AVERAGE TEST PREDS\npred_lgb /= FOLDS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:04:14.665133Z","iopub.execute_input":"2024-12-10T08:04:14.665725Z","iopub.status.idle":"2024-12-10T08:05:12.453423Z","shell.execute_reply.started":"2024-12-10T08:04:14.665693Z","shell.execute_reply":"2024-12-10T08:05:12.452425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\ny_pred = train[[\"ID\"]].copy()\ny_pred[\"prediction\"] = oof_lgb\nm = score(y_true.copy(), y_pred.copy(), \"ID\")\nprint(f\"\\nOverall CV for LightGBM KaplanMeier =\",m)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:05:12.454673Z","iopub.execute_input":"2024-12-10T08:05:12.454976Z","iopub.status.idle":"2024-12-10T08:05:12.779457Z","shell.execute_reply.started":"2024-12-10T08:05:12.454947Z","shell.execute_reply":"2024-12-10T08:05:12.778666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_importance = model_lgb.feature_importances_ \nimportance_df = pd.DataFrame({\n    \"Feature\": FEATURES,\n    \"Importance\": feature_importance\n}).sort_values(by=\"Importance\", ascending=False)\nplt.figure(figsize=(10, 15))\nplt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='skyblue')\nplt.xlabel(\"Importance (Gain)\")\nplt.ylabel(\"Feature\")\nplt.title(\"LightGBM KaplanMeier Feature Importance\")\nplt.gca().invert_yaxis()  # Flip features for better readability\nplt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T08:05:12.780451Z","iopub.execute_input":"2024-12-10T08:05:12.780738Z","iopub.status.idle":"2024-12-10T08:05:13.407709Z","shell.execute_reply.started":"2024-12-10T08:05:12.780711Z","shell.execute_reply":"2024-12-10T08:05:13.406857Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XGBoost with Survival:Cox\nWe train XGBoost using Survival:Cox loss for 10 folds and achieve **CV=672**!","metadata":{}},{"cell_type":"code","source":"# SURVIVAL COX NEEDS THIS TARGET (TO DIGEST EFS AND EFS_TIME)\ntrain[\"efs_time2\"] = train.efs_time.copy()\ntrain.loc[train.efs==0,\"efs_time2\"] *= -1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:05:13.408847Z","iopub.execute_input":"2024-12-10T08:05:13.409132Z","iopub.status.idle":"2024-12-10T08:05:13.417041Z","shell.execute_reply.started":"2024-12-10T08:05:13.409105Z","shell.execute_reply":"2024-12-10T08:05:13.416098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FOLDS = 10\nkf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n    \noof_xgb_cox = np.zeros(len(train))\npred_xgb_cox = np.zeros(len(test))\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {i+1}\")\n    print(\"#\"*25)\n    \n    x_train = train.loc[train_index,FEATURES].copy()\n    y_train = train.loc[train_index,\"efs_time2\"]    \n    x_valid = train.loc[test_index,FEATURES].copy()\n    y_valid = train.loc[test_index,\"efs_time2\"]\n    x_test = test[FEATURES].copy()\n\n    model_xgb_cox = XGBRegressor(\n        device=\"cuda\",\n        max_depth=3,  \n        colsample_bytree=0.5,  \n        subsample=0.8,  \n        n_estimators=2000,  \n        learning_rate=0.02,  \n        enable_categorical=True,\n        min_child_weight=80,\n        objective='survival:cox',\n        eval_metric='cox-nloglik',\n    )\n    model_xgb_cox.fit(\n        x_train, y_train,\n        eval_set=[(x_valid, y_valid)],  \n        verbose=500  \n    )\n    \n    # INFER OOF\n    oof_xgb_cox[test_index] = model_xgb_cox.predict(x_valid)\n    # INFER TEST\n    pred_xgb_cox += model_xgb_cox.predict(x_test)\n\n# COMPUTE AVERAGE TEST PREDS\npred_xgb_cox /= FOLDS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:05:13.418484Z","iopub.execute_input":"2024-12-10T08:05:13.418838Z","iopub.status.idle":"2024-12-10T08:06:45.958246Z","shell.execute_reply.started":"2024-12-10T08:05:13.418809Z","shell.execute_reply":"2024-12-10T08:06:45.957536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\ny_pred = train[[\"ID\"]].copy()\ny_pred[\"prediction\"] = oof_xgb_cox\nm = score(y_true.copy(), y_pred.copy(), \"ID\")\nprint(f\"\\nOverall CV for XGBoost Survival:Cox =\",m)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:06:45.959332Z","iopub.execute_input":"2024-12-10T08:06:45.959926Z","iopub.status.idle":"2024-12-10T08:06:46.276248Z","shell.execute_reply.started":"2024-12-10T08:06:45.959892Z","shell.execute_reply":"2024-12-10T08:06:46.275500Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_importance = model_xgb_cox.feature_importances_\nimportance_df = pd.DataFrame({\n    \"Feature\": FEATURES,  # Replace FEATURES with your list of feature names\n    \"Importance\": feature_importance\n}).sort_values(by=\"Importance\", ascending=False)\nplt.figure(figsize=(10, 15))\nplt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\nplt.xlabel(\"Importance\")\nplt.ylabel(\"Feature\")\nplt.title(\"XGBoost Survival:Cox Feature Importance\")\nplt.gca().invert_yaxis()  # Flip features for better readability\nplt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T08:06:46.277265Z","iopub.execute_input":"2024-12-10T08:06:46.277652Z","iopub.status.idle":"2024-12-10T08:06:46.891840Z","shell.execute_reply.started":"2024-12-10T08:06:46.277614Z","shell.execute_reply":"2024-12-10T08:06:46.891074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CatBoost with Survival:Cox\nWe train CatBoost using Survival:Cox loss for 10 folds and achieve **CV=671**!","metadata":{}},{"cell_type":"code","source":"FOLDS = 10\nkf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n    \noof_cat_cox = np.zeros(len(train))\npred_cat_cox = np.zeros(len(test))\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n\n    print(\"#\"*25)\n    print(f\"### Fold {i+1}\")\n    print(\"#\"*25)\n    \n    x_train = train.loc[train_index,FEATURES].copy()\n    y_train = train.loc[train_index,\"efs_time2\"]    \n    x_valid = train.loc[test_index,FEATURES].copy()\n    y_valid = train.loc[test_index,\"efs_time2\"]\n    x_test = test[FEATURES].copy()\n\n    model_cat_cox = CatBoostRegressor(\n        loss_function=\"Cox\",\n        #task_type=\"GPU\",   \n        iterations=400,     \n        learning_rate=0.1,  \n        grow_policy='Lossguide',\n        use_best_model=False,\n    )\n    model_cat_cox.fit(x_train,y_train,\n              eval_set=(x_valid, y_valid),\n              cat_features=CATS,\n              verbose=100)\n    \n    # INFER OOF\n    oof_cat_cox[test_index] = model_cat_cox.predict(x_valid)\n    # INFER TEST\n    pred_cat_cox += model_cat_cox.predict(x_test)\n\n# COMPUTE AVERAGE TEST PREDS\npred_cat_cox /= FOLDS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:06:46.892928Z","iopub.execute_input":"2024-12-10T08:06:46.893280Z","iopub.status.idle":"2024-12-10T08:10:44.391003Z","shell.execute_reply.started":"2024-12-10T08:06:46.893241Z","shell.execute_reply":"2024-12-10T08:10:44.390109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\ny_pred = train[[\"ID\"]].copy()\ny_pred[\"prediction\"] = oof_cat_cox\nm = score(y_true.copy(), y_pred.copy(), \"ID\")\nprint(f\"\\nOverall CV for CatBoost Survival:Cox =\",m)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:10:44.392055Z","iopub.execute_input":"2024-12-10T08:10:44.392366Z","iopub.status.idle":"2024-12-10T08:10:44.710058Z","shell.execute_reply.started":"2024-12-10T08:10:44.392327Z","shell.execute_reply":"2024-12-10T08:10:44.709303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_importance = model_cat_cox.get_feature_importance()\nimportance_df = pd.DataFrame({\n    \"Feature\": FEATURES, \n    \"Importance\": feature_importance\n}).sort_values(by=\"Importance\", ascending=False)\nplt.figure(figsize=(10, 15))\nplt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\nplt.xlabel(\"Importance\")\nplt.ylabel(\"Feature\")\nplt.title(\"CatBoost Survival:Cox Feature Importance\")\nplt.gca().invert_yaxis()  # Flip features for better readability\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:10:44.710976Z","iopub.execute_input":"2024-12-10T08:10:44.711240Z","iopub.status.idle":"2024-12-10T08:10:45.314574Z","shell.execute_reply.started":"2024-12-10T08:10:44.711214Z","shell.execute_reply":"2024-12-10T08:10:45.313834Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensemble CAT and XGB and LGB using LGBM\n","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Prepare stacked features (out-of-fold predictions) for training\nstacked_features = np.vstack([\n    oof_xgb,\n    oof_cat,\n    oof_lgb,\n    oof_xgb_cox,\n    oof_cat_cox,\n]).T\n\n# Prepare target variable\ny_train = train[\"y\"]\n\n# Train meta-model using LightGBM\nmeta_model_lgb = LGBMRegressor(\n    n_estimators=100,\n    learning_rate=0.05,\n    max_depth=3,\n    random_state=42\n)\nmeta_model_lgb.fit(stacked_features, y_train)\n\n# Prepare stacked features for test set predictions\nstacked_test = np.vstack([\n    pred_xgb,\n    pred_cat,\n    pred_lgb,\n    pred_xgb_cox,\n    pred_cat_cox,\n]).T\n\n# Make predictions for training set (oof predictions) and test set\ny_pred_train = pd.DataFrame()\ny_pred_train[\"ID\"] = train[\"ID\"]\ny_pred_train[\"prediction\"] = meta_model_lgb.predict(stacked_features)\n\ny_pred_test = pd.DataFrame()\ny_pred_test[\"ID\"] = test[\"ID\"]\ny_pred_test[\"prediction\"] = meta_model_lgb.predict(stacked_test)\n\n# Evaluate performance on the training set\ny_true = train[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\nm_train = score(y_true.copy(), y_pred_train.copy(), \"ID\")\nprint(f\"\\nOverall CV for Gradient Boosting Meta-Model (Training) = {m_train}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:10:45.319076Z","iopub.execute_input":"2024-12-10T08:10:45.319456Z","iopub.status.idle":"2024-12-10T08:10:45.761222Z","shell.execute_reply.started":"2024-12-10T08:10:45.319415Z","shell.execute_reply":"2024-12-10T08:10:45.760294Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Submission CSV","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the sample submission file\nsub = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\n\n# Use predictions from the Gradient Boosting meta-model\nsub[\"prediction\"] = y_pred_test[\"prediction\"]\n\n# Save the submission file\nsub.to_csv(\"submission.csv\", index=False)\n\n# Output the shape and first few rows of the submission file\nprint(\"Sub shape:\", sub.shape)\nprint(sub.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:10:45.762333Z","iopub.execute_input":"2024-12-10T08:10:45.763067Z","iopub.status.idle":"2024-12-10T08:10:45.778143Z","shell.execute_reply.started":"2024-12-10T08:10:45.763019Z","shell.execute_reply":"2024-12-10T08:10:45.777355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}